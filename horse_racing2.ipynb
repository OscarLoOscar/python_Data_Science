{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import shlex\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from google.colab import drive\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.model_selection as model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import re\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HKJCWebScraper:\n",
    "    def __init__(self):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"--remote-debugging-port=9222\")\n",
    "        self.browser = webdriver.Chrome(options=chrome_options)\n",
    "        self.base_url = 'https://racing.hkjc.com/racing/information/Chinese/Racing/LocalResults.aspx?RaceDate='\n",
    "\n",
    "    def get_dates(self):\n",
    "        self.browser.get(self.base_url + '2024/05/29')  # Example date to access the page\n",
    "        try:\n",
    "            # Wait for the select element to be present\n",
    "            select_element = WebDriverWait(self.browser, 20).until(\n",
    "                EC.presence_of_element_located((By.ID, \"selectId\"))\n",
    "            )\n",
    "            options = WebDriverWait(self.browser, 20).until(\n",
    "                EC.presence_of_all_elements_located((By.TAG_NAME, \"option\"))\n",
    "            )\n",
    "            dates = [option.get_attribute(\"value\") for option in options]\n",
    "            return dates\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while fetching dates: {e}\")\n",
    "            return []\n",
    "\n",
    "    def scrape_data_for_date(self, date):\n",
    "        self.browser.get(self.base_url + date)\n",
    "        time.sleep(3)  # Wait for page to load\n",
    "        soup = BeautifulSoup(self.browser.page_source, 'html.parser')\n",
    "\n",
    "        # Extract data from race_tab\n",
    "        race_tab_data = []\n",
    "        race_tab = soup.find('table', class_='race_tab')\n",
    "        if race_tab:\n",
    "            rows = race_tab.find_all('tr')[1:]  # Skip the header row\n",
    "            for row in rows:\n",
    "                race_tab_data.append([cell.get_text(strip=True) for cell in row.find_all('td')])\n",
    "\n",
    "        # Extract data from performance table\n",
    "        performance_data = []\n",
    "        performance_table = soup.find('table', class_='f_tac table_bd draggable')\n",
    "        if performance_table:\n",
    "            rows = performance_table.find_all('tr')\n",
    "            for row in rows:\n",
    "                performance_data.append([cell.get_text(strip=True) for cell in row.find_all('td')])\n",
    "\n",
    "        # Extract data from dividend_tab\n",
    "        # dividend_data = []\n",
    "        # dividend_table = soup.find('table', class_='table_bd f_tac f_fs13 f_fl')\n",
    "        # if dividend_table:\n",
    "        #     rows = dividend_table.find_all('tr')\n",
    "        #     for row in rows:\n",
    "        #         dividend_data.append([cell.get_text(strip=True) for cell in row.find_all('td')])\n",
    "\n",
    "        # return race_tab_data, performance_data, dividend_data\n",
    "        return race_tab_data, performance_data\n",
    "\n",
    "    def close(self):\n",
    "        self.browser.quit()\n",
    "\n",
    "scraper = HKJCWebScraper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data = []\n",
    "# dates = scraper.get_dates()\n",
    "# for date in dates:\n",
    "#     print(f\"Scraping data for {date}\")\n",
    "#     try:\n",
    "#         data = scraper.scrape_data_for_date(date)\n",
    "#         all_data.append({date: data})\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to scrape data for {date}: {e}\")\n",
    "\n",
    "# file_path = '/content/drive/My Drive/horse_data.xlsx'\n",
    "# all_data.to_excel(file_path, index=False)\n",
    "def parse_data(all_data):\n",
    "    data_list = []\n",
    "    for race in all_data:\n",
    "        for date, (meta, race_results) in race.items():\n",
    "            if not race_results:  # 檢查 race_results 是否為空\n",
    "                print(f\"No race results for {date}\")\n",
    "                continue\n",
    "\n",
    "            columns = race_results[0]\n",
    "            for result in race_results[1:]:\n",
    "                if len(result) != len(columns):\n",
    "                    print(f\"Mismatch in columns and data for {date}: {result}\")\n",
    "                    continue\n",
    "\n",
    "                race_dict = {col: val for col, val in zip(columns, result)}\n",
    "                race_dict['date'] = date\n",
    "                data_list.append(race_dict)\n",
    "\n",
    "    return pd.DataFrame(data_list)\n",
    "\n",
    "df = parse_data(all_data)\n",
    "\n",
    "# 保存為Excel文件\n",
    "file_path = '/content/drive/My Drive/horse_data.xlsx'\n",
    "df.to_excel(file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取數據\n",
    "file_path = '/content/drive/My Drive/horse_data.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 顯示前幾行數據\n",
    "# print(df.head())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Step 3: Filter the data based on '名次'\n",
    "  def clean_ranking(x):\n",
    "      if pd.isna(x):\n",
    "          return np.nan\n",
    "      if isinstance(x, str) and '平頭馬' in x:\n",
    "          return int(x.replace('平頭馬', ''))\n",
    "      try:\n",
    "          return int(x)\n",
    "      except ValueError:\n",
    "          return np.nan\n",
    "\n",
    "  if '名次' in df.columns:\n",
    "      df['名次'] = df['名次'].apply(clean_ranking)\n",
    "  else:\n",
    "      print(\"Column '名次' does not exist in the DataFrame.\")\n",
    "\n",
    "  # Step 4: Select relevant columns and drop NaN values\n",
    "  relevant_columns = ['馬號', '騎師', '練馬師', '實際負磅', '排位體重', '檔位', '名次']\n",
    "  df = df[relevant_columns].dropna()\n",
    "\n",
    "  # Step 5: Filter out rows with non-numeric '檔位' values and convert to integers\n",
    "  df = df[df['檔位'].apply(lambda x: str(x).isdigit())]\n",
    "  df['檔位'] = df['檔位'].astype(int)\n",
    "\n",
    "  # Step 6: Filter out strange draw values (e.g., negative values, or values beyond a realistic range)\n",
    "  df = df[(df['檔位'] > 0) & (df['檔位'] <= 20)]  # Assuming realistic range is 1 to 20\n",
    "\n",
    "  # Step 7: Encode categorical columns\n",
    "  label_encoder_jockey = LabelEncoder()\n",
    "  label_encoder_trainer = LabelEncoder()\n",
    "\n",
    "  df['騎師'] = label_encoder_jockey.fit_transform(df['騎師'])\n",
    "  df['練馬師'] = label_encoder_trainer.fit_transform(df['練馬師'])\n",
    "\n",
    "  df = pd.get_dummies(df, columns=['騎師', '練馬師'])\n",
    "\n",
    "  for col in df.select_dtypes(include=['bool']).columns:\n",
    "      df[col] = df[col].astype(int)\n",
    "\n",
    "  # Step 8: Add a new column 'race_id' based on existing columns\n",
    "  df['race_id'] = df.index + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徵工程\n",
    "def feature_engineering(df):\n",
    "    df['排位體重'] = pd.to_numeric(df['排位體重'], errors='coerce')\n",
    "    df['實際負磅'] = pd.to_numeric(df['實際負磅'], errors='coerce')\n",
    "\n",
    "    # 新的特徵創建，例如馬匹的平均速度\n",
    "    df['average_speed'] = df['排位體重'] / df['實際負磅']\n",
    "    return df\n",
    "\n",
    "df = feature_engineering(df)\n",
    "\n",
    "# Define features and target\n",
    "features = df.drop(columns=['名次', '馬號', 'race_id'])\n",
    "target = df['名次']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Dense(512, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='linear')  # Using linear activation for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=2000, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Absolute Error: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Step 2: Define a Function to Predict Top 4 Horses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_top_4(model, scaler, label_encoder_jockey, label_encoder_trainer, input_data):\n",
    "    input_df = pd.DataFrame(input_data, columns=['馬號', '馬名', '檔位', '負磅', '騎師', '練馬師', '馬匹體重'])\n",
    "\n",
    "    # Preserve '馬號' and '馬名' columns\n",
    "    horse_ids = input_df['馬號']\n",
    "    horse_names = input_df['馬名']\n",
    "\n",
    "    # Encode categorical features\n",
    "    input_df['騎師'] = label_encoder_jockey.transform(input_df['騎師'])\n",
    "    input_df['練馬師'] = label_encoder_trainer.transform(input_df['練馬師'])\n",
    "    input_df = pd.get_dummies(input_df, columns=['騎師', '練馬師'])\n",
    "\n",
    "    # Reindex to match the training feature set, excluding '馬號' and '馬名'\n",
    "    feature_columns = [col for col in features.columns if col not in ['馬號', '馬名']]\n",
    "    input_df = input_df.reindex(columns=feature_columns, fill_value=0)\n",
    "\n",
    "    # Normalize the input features\n",
    "    input_scaled = scaler.transform(input_df)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(input_scaled)\n",
    "    input_df['prediction'] = predictions\n",
    "\n",
    "    # Add back '馬號' and '馬名' columns\n",
    "    input_df['馬號'] = horse_ids\n",
    "    input_df['馬名'] = horse_names\n",
    "\n",
    "    # Get the top 4 horses with the highest probabilities of winning\n",
    "    top_4_horses = input_df.nlargest(4, 'prediction')\n",
    "    return top_4_horses[['馬號', '馬名', 'prediction']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Input Data then Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example input data\n",
    "input_data = [\n",
    "    [1, '勁無敵', 5, 135, '蔡明紹','羅富全','1039'],\n",
    "    [2, '同滿滿', 10, 135, '霍宏聲','伍鵬志','1082'],\n",
    "    [3, '會展二號', 4, 134, '鍾易禮','告東尼','1145'],\n",
    "    [4, '威武良駒', 7, 133, '布文','姚本輝',''],\n",
    "    [5,'中華威威',8,132,'黃智弘','徐雨石','1243'],\n",
    "    [6,'有你有我',12,130, '艾道拿','廖康銘','973'],\n",
    "    [7,'飛躍精英',3,129, '巴度','賀賢','1088'],\n",
    "    [8,'佳景臨門',1,128, '艾兆禮','葉楚航','1119'],\n",
    "    [9,'萬事有',6,124,'希威森','容天鵬','1242'],\n",
    "    [10,'友誼至佳',9,119,'董明朗','韋達','1182'],\n",
    "    [11,'月球',11,118,'湯普新','黎昭昇','1154'],\n",
    "    [12,'錢途光明',2,115,'潘明輝','丁冠豪','1068']\n",
    "]\n",
    "\n",
    "top_4_horses = predict_top_4(model, scaler, label_encoder_jockey, label_encoder_trainer, input_data)\n",
    "print(top_4_horses)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
