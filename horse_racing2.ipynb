{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import shlex\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from google.colab import drive\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.model_selection as model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HKJCWebScraper:\n",
    "    def __init__(self):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"--remote-debugging-port=9222\")\n",
    "        self.browser = webdriver.Chrome(options=chrome_options)\n",
    "        self.base_url = 'https://racing.hkjc.com/racing/information/Chinese/Racing/LocalResults.aspx?RaceDate='\n",
    "\n",
    "    def get_dates(self):\n",
    "        self.browser.get(self.base_url + '2024/05/29')  # Example date to access the page\n",
    "        try:\n",
    "            # Wait for the select element to be present\n",
    "            select_element = WebDriverWait(self.browser, 20).until(\n",
    "                EC.presence_of_element_located((By.ID, \"selectId\"))\n",
    "            )\n",
    "            options = WebDriverWait(self.browser, 20).until(\n",
    "                EC.presence_of_all_elements_located((By.TAG_NAME, \"option\"))\n",
    "            )\n",
    "            dates = [option.get_attribute(\"value\") for option in options]\n",
    "            return dates\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while fetching dates: {e}\")\n",
    "            return []\n",
    "\n",
    "    def scrape_data_for_date(self, date):\n",
    "        self.browser.get(self.base_url + date)\n",
    "        time.sleep(3)  # Wait for page to load\n",
    "        soup = BeautifulSoup(self.browser.page_source, 'html.parser')\n",
    "\n",
    "        # Extract data from race_tab\n",
    "        race_tab_data = []\n",
    "        race_tab = soup.find('table', class_='race_tab')\n",
    "        if race_tab:\n",
    "            rows = race_tab.find_all('tr')[1:]  # Skip the header row\n",
    "            for row in rows:\n",
    "                race_tab_data.append([cell.get_text(strip=True) for cell in row.find_all('td')])\n",
    "\n",
    "        # Extract data from performance table\n",
    "        performance_data = []\n",
    "        performance_table = soup.find('table', class_='f_tac table_bd draggable')\n",
    "        if performance_table:\n",
    "            rows = performance_table.find_all('tr')\n",
    "            for row in rows:\n",
    "                performance_data.append([cell.get_text(strip=True) for cell in row.find_all('td')])\n",
    "\n",
    "        # Extract data from dividend_tab\n",
    "        # dividend_data = []\n",
    "        # dividend_table = soup.find('table', class_='table_bd f_tac f_fs13 f_fl')\n",
    "        # if dividend_table:\n",
    "        #     rows = dividend_table.find_all('tr')\n",
    "        #     for row in rows:\n",
    "        #         dividend_data.append([cell.get_text(strip=True) for cell in row.find_all('td')])\n",
    "\n",
    "        # return race_tab_data, performance_data, dividend_data\n",
    "        return race_tab_data, performance_data\n",
    "\n",
    "    def close(self):\n",
    "        self.browser.quit()\n",
    "\n",
    "scraper = HKJCWebScraper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data = []\n",
    "# dates = scraper.get_dates()\n",
    "# for date in dates:\n",
    "#     print(f\"Scraping data for {date}\")\n",
    "#     try:\n",
    "#         data = scraper.scrape_data_for_date(date)\n",
    "#         all_data.append({date: data})\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to scrape data for {date}: {e}\")\n",
    "\n",
    "# file_path = '/content/drive/My Drive/horse_data.xlsx'\n",
    "# all_data.to_excel(file_path, index=False)\n",
    "def parse_data(all_data):\n",
    "    data_list = []\n",
    "    for race in all_data:\n",
    "        for date, (meta, race_results) in race.items():\n",
    "            if not race_results:  # 檢查 race_results 是否為空\n",
    "                print(f\"No race results for {date}\")\n",
    "                continue\n",
    "            \n",
    "            columns = race_results[0]\n",
    "            for result in race_results[1:]:\n",
    "                if len(result) != len(columns):\n",
    "                    print(f\"Mismatch in columns and data for {date}: {result}\")\n",
    "                    continue\n",
    "                \n",
    "                race_dict = {col: val for col, val in zip(columns, result)}\n",
    "                race_dict['date'] = date\n",
    "                data_list.append(race_dict)\n",
    "    \n",
    "    return pd.DataFrame(data_list)\n",
    "\n",
    "df = parse_data(all_data)\n",
    "\n",
    "# 保存為Excel文件\n",
    "file_path = '/content/drive/My Drive/horse_data.xlsx'\n",
    "df.to_excel(file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取數據\n",
    "file_path = '/content/drive/My Drive/horse_data.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 顯示前幾行數據\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 過濾不含數字的'名次'數據\n",
    "df = df[pd.to_numeric(df['名次'], errors='coerce').notnull()]\n",
    "# 過濾和清理'名次'列\n",
    "df['名次'] = df['名次'].apply(lambda x: re.sub(r'\\D', '', str(x)))  # 去掉非数字字符\n",
    "df = df[df['名次'] != '']  # 过滤掉空字符串\n",
    "df['名次'] = df['名次'].astype(int)  # 将'名次'转换为整数\n",
    "\n",
    "# 處理無效值\n",
    "df['實際負磅'] = pd.to_numeric(df['實際負磅'], errors='coerce')\n",
    "df['排位體重'] = pd.to_numeric(df['排位體重'], errors='coerce')\n",
    "df['檔位'] = pd.to_numeric(df['檔位'], errors='coerce')\n",
    "df['獨贏賠率'] = pd.to_numeric(df['獨贏賠率'], errors='coerce')\n",
    "df['完成時間'] = df['完成時間'].apply(lambda x: float(x.split(':')[0]) * 60 + float(x.split(':')[1]) if isinstance(x, str) else None)\n",
    "\n",
    "# 刪除含有 NaN 的行\n",
    "df.dropna()\n",
    "\n",
    "# 將數值類型轉換為整數\n",
    "df['實際負磅'] = df['實際負磅'].astype(int)\n",
    "df['排位體重'] = df['排位體重'].astype(int)\n",
    "df['檔位'] = df['檔位'].astype(int)\n",
    "df['獨贏賠率'] = df['獨贏賠率'].astype(float)\n",
    "\n",
    "# 將類別特徵轉換為數值特徵\n",
    "label_encoders = {}\n",
    "for column in ['馬號', '馬名', '騎師', '練馬師', '實際負磅', '排位體重', '檔位', '完成時間', '獨贏賠率']:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    df[column] = label_encoders[column].fit_transform(df[column])\n",
    "\n",
    "# 選擇特徵和標籤\n",
    "features = ['馬號', '馬名', '騎師', '練馬師', '實際負磅', '排位體重', '檔位', '完成時間', '獨贏賠率']\n",
    "X = df[features]\n",
    "y = df['名次']\n",
    "\n",
    "\n",
    "\n",
    "# 標籤二值化（假設要預測名次為1、2、3、4的馬匹）\n",
    "y = (y <= 4).astype(int)\n",
    "\n",
    "# 分割數據集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 標準化數據\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 建立BP神經網絡模型\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=X_train.shape[1], activation='relu')) # 增加第一層神經元數量\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu')) # 增加第二層神經元數量\n",
    "model.add(Dense(32, activation='relu')) # 添加第三層\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 更改激活函數\n",
    "# model = Sequential()\n",
    "# model.add(Dense(64, input_dim=X_train.shape[1], activation='tanh'))  # 使用tanh激活函數\n",
    "# model.add(Dense(32, activation='tanh'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# 訓練模型\n",
    "model.fit(X_train, y_train, epochs=2000, batch_size=50, validation_split=0.2)\n",
    "# epochs：訓練過程中的 epoch 數量，即模型將完整遍歷訓練集的次數。\n",
    "\n",
    "# batch_size：每個批次（batch）中包含的樣本數量。在每個 epoch 中，訓練數據將被劃分為多個批次，每個批次中的樣本將被用於更新模型的權重。選擇適當的批次大小可以影響訓練速度和模型的性能。\n",
    "\n",
    "# validation_split：用於驗證的訓練集的比例。例如，如果設置為0.2，則將訓練集的20％用於驗證，而80％用於訓練。這個驗證集將用於每個 epoch 結束時計算模型的驗證損失和指標。\n",
    "\n",
    "# 評估模型\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy : \")\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# 預測\n",
    "predictions = model.predict(X_test)\n",
    "predictions = (predictions > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 顯示預測結果\n",
    "for i in range(10):\n",
    "    print(f'Actual: {y_test.iloc[i]}, Predicted: {predictions[i][0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided input data with only relevant features\n",
    "# '馬號', '馬名', '騎師', '練馬師', '實際負磅', '排位體重', '檔位', '完成時間', '獨贏賠率'\n",
    "input_data = [\n",
    "    [1, 'H486', '竣誠駒', 12, 135, '鍾易禮', '告東尼', 1165, 40, 'TT'],\n",
    "    [2, 'H083', '滿載歸來', 13, 133, '布文', '容天鵬', 1215, 38, 'B/TT'],\n",
    "    [3, 'E166', '樂天派', 3, 132, '董明朗', '大衛希斯', 1132, 37, 'CP2'],\n",
    "    [4, 'E025', '怡昌勇士', 6, 131, '田泰安', '賀賢', 1101, 36, 'CP/XB'],\n",
    "    [5, 'G295', '神舟飛駒', 9, 129, '班德禮', '韋達', 1058, 34, 'B/TT'],\n",
    "    [6, 'H196', '上市魅力', 5, 129, '艾兆禮', '蘇偉賢', 1092, 34, 'P/TT'],\n",
    "    [7, 'G322', '國大合', 1, 129, '希威森', '廖康銘', 1054, 34, 'B'],\n",
    "    [8, 'D235', '爸巴閉', 8, 123, '湯普新', '徐雨石', 1095, 28, 'TT-'],\n",
    "    [9, 'E194', '符號', 2, 122, '巴度', '徐雨石', 997, 27, ''],\n",
    "    [10, 'G072', '喜悅一生', 4, 121, '巫顯東 ', '鄭俊偉', 1154, 26, 'B/TT'],\n",
    "    [11, 'H040', '小鳥', 10, 117, '蔡明紹', '葉楚航', 1011, 22, 'B'],\n",
    "    [12, 'H285', '鑽石福將', 11, 115, '潘明輝', '蔡約翰', 1118, 17, ''],\n",
    "    [13, 'E409', '綠登', 7, 115, '楊明綸', '蘇偉賢', 1112, 16, 'PC/TT']\n",
    "]\n",
    "# Convert input data to DataFrame with only relevant features\n",
    "input_df = pd.DataFrame(input_data, columns=['馬號','綵衣','馬名','檔位','負磅','騎師','練馬師','馬匹體重','評分','配備'])\n",
    "\n",
    "# Convert categorical features to one-hot encoding\n",
    "input_df = pd.get_dummies(input_df, columns=['馬名', '檔位', '負磅', '騎師', '練馬師','馬匹體重'])\n",
    "for column, dtype in input_df.dtypes.items():\n",
    "    print(f'{column}: {dtype}')\n",
    "\n",
    "\n",
    "# 將非數字類型的特徵名稱從 DataFrame 中刪除\n",
    "input_df = input_df.drop(columns=['綵衣', '配備'])\n",
    "\n",
    "# 將獨熱編碼應用於對象類型的特徵\n",
    "# input_df = pd.get_dummies(input_df, columns=['綵衣', '配備'])\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(input_df)\n",
    "\n",
    "# Print the predictions\n",
    "for i, prediction in enumerate(predictions, start=1):\n",
    "     print(f'Rank {i}: Horse {input_df.loc[i-1, \"Feature3\"]} (Probability: {prediction[0]})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_all_data(all_data):\n",
    "    run_list = []\n",
    "\n",
    "    for race_data in all_data:\n",
    "        for date, (empty_list, horse_info) in race_data.items():\n",
    "            # horse_info contains relevant race details\n",
    "            for horse in horse_info[1:]:  # Skip the header row\n",
    "              if len(horse)>=12:\n",
    "                run_list.append([\n",
    "                    date,                # race_id as date\n",
    "                    horse[1],            # horse_id\n",
    "                    horse[0],            # position\n",
    "                    horse[3],            # jockey\n",
    "                    horse[4],            # trainer\n",
    "                    horse[5],            # actual weight\n",
    "                    horse[6],            # declared weight\n",
    "                    horse[7],            # draw\n",
    "                    horse[10],           # finish time\n",
    "                    horse[11],           # win odds\n",
    "                ])\n",
    "              else:\n",
    "                  print(f\"Skipping incomplete entry for date {date}: {horse}\")\n",
    "    # Convert lists to DataFrame\n",
    "    runs_df = pd.DataFrame(run_list, columns=[\n",
    "        'race_id', 'horse_id', 'position', 'jockey', 'trainer', 'actual_weight',\n",
    "        'declared_weight', 'draw', 'finish_time', 'win_odds'\n",
    "    ])\n",
    "\n",
    "    return runs_df\n",
    "# Process all_data\n",
    "runs_df = process_all_data(all_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(runs_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns and drop NaN values\n",
    "runs_df = runs_df[['race_id', 'horse_id','position', 'jockey', 'trainer', 'actual_weight', 'declared_weight', 'draw', 'finish_time','win_odds']]\n",
    "runs_df = runs_df.dropna()\n",
    "\n",
    "# Filter out rows with non-numeric 'draw' values\n",
    "runs_df = runs_df[pd.to_numeric(runs_df['draw'], errors='coerce').notnull()]\n",
    "\n",
    "# Convert 'draw' column to integers\n",
    "runs_df['draw'] = runs_df['draw'].astype(int)\n",
    "\n",
    "# Filter out strange draw values\n",
    "strange_draw_index = runs_df[runs_df['draw'] > 14].index\n",
    "runs_df = runs_df.drop(strange_draw_index)\n",
    "\n",
    "# Encode categorical columns: jockey and trainer\n",
    "jockey_encoder = preprocessing.LabelEncoder()\n",
    "runs_df['jockey'] = jockey_encoder.fit_transform(runs_df['jockey'])\n",
    "trainer_encoder = preprocessing.LabelEncoder()\n",
    "runs_df['trainer'] = trainer_encoder.fit_transform(runs_df['trainer'])\n",
    "\n",
    "print(runs_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the DataFrame preparation steps\n",
    "def prepare_dataframe(df):\n",
    "    # Select relevant columns and drop NaN values\n",
    "    relevant_columns = ['race_id', 'horse_id', 'position', 'draw']\n",
    "    df = df[relevant_columns]\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Filter out rows with non-numeric 'draw' values\n",
    "    df = df[pd.to_numeric(df['draw'], errors='coerce').notnull()]\n",
    "\n",
    "    # Convert 'draw' column to integers\n",
    "    df['draw'] = df['draw'].astype(int)\n",
    "\n",
    "    # Filter out strange draw values\n",
    "    df = df[df['draw'] <= 14]\n",
    "\n",
    "    return df\n",
    "\n",
    "# Prepare the DataFrame\n",
    "runs_df = prepare_dataframe(runs_df)\n",
    "\n",
    "# Pivot the DataFrame\n",
    "runs_df_pivot = runs_df.pivot(index='race_id', columns='draw', values='position')\n",
    "\n",
    "# Fill NaNs with 0\n",
    "runs_df_filled = runs_df_pivot.fillna(0)\n",
    "\n",
    "print(runs_df_filled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the columns containing target variables are converted to numeric data type\n",
    "data[data.columns[-14:]] = data[data.columns[-14:]].astype(float)\n",
    "\n",
    "# Clean the data to remove non-numeric strings\n",
    "data = data[data[data.columns[-14:]].applymap(lambda x: isinstance(x, (int, float)))]\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop(data.columns[-14:], axis=1)  # Exclude the last 14 columns which are the target variables\n",
    "y = data[data.columns[-14:]].applymap(lambda x: 1.0 if 0.5 < float(x) < 1.5 else 0.0)\n",
    "\n",
    "# Exclude 'race_id' column from features\n",
    "X = X.drop('race_id', axis=1)\n",
    "\n",
    "# Standardize the features\n",
    "ss = preprocessing.StandardScaler()\n",
    "X = pd.DataFrame(ss.fit_transform(X), columns=X.columns)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace NaN and infinite values with zeros\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)\n",
    "\n",
    "# Define and compile the model\n",
    "model = Sequential([\n",
    "    Dense(96, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(14, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=Adam(5e-04),\n",
    "              loss=CategoricalCrossentropy(),\n",
    "              metrics=[Precision(name='precision')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(len(X_train)).batch(500)\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "validation_dataset = validation_dataset.shuffle(len(X_test)).batch(500)\n",
    "\n",
    "# Train the model\n",
    "print(\"Start training...\\n\")\n",
    "history = model.fit(train_dataset, epochs=200, validation_data=validation_dataset)\n",
    "print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(precision) + 1)\n",
    "\n",
    "plt.plot(epochs, precision, 'b', label='Training precision')\n",
    "plt.plot(epochs, val_precision, 'r', label='Validation precision')\n",
    "plt.title('Training and validation precision')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided input data\n",
    "input_data = [\n",
    "    '第1場02/06/2024', '星期日', '16:00', '第五班', '2000米', '草地', '沙田海讓賽', \"B\",\n",
    "    # Horse information\n",
    "    [1, 'H486', '竣誠駒', 12, 135, '鍾易禮 (-3)', '告東尼', 1165, 40, 'TT', [5, 9, 14, 10, 12, 11]],\n",
    "    [2, 'H083', '滿載歸來', 13, 133, '布文', '容天鵬', 1215, 38, 'B/TT', [10, 7, 7, 10, 3, 2]],\n",
    "    [3, 'E166', '樂天派', 3, 132, '董明朗', '大衛希斯', 1132, 37, 'CP2', [10, 9, 11, 10, 12, 7]],\n",
    "    [4, 'E025', '怡昌勇士', 6, 131, '田泰安', '賀賢', 1101, 36, 'CP/XB', [6, 8, 3, 11, 9, 9]],\n",
    "    [5, 'G295', '神舟飛駒', 9, 129, '班德禮', '韋達', 1058, 34, 'B/TT', [3, 8, 12, 10, 10, 6]],\n",
    "    [6, 'H196', '上市魅力', 5, 129, '艾兆禮', '蘇偉賢', 1092, 34, 'P/TT', [2, 2, 11, 6, 7, 8]],\n",
    "    [7, 'G322', '國大合', 1, 129, '希威森', '廖康銘', 1054, 34, 'B', [4, 2, 10, 11, 10, 4]],\n",
    "    [8, 'D235', '爸巴閉', 8, 123, '湯普新', '徐雨石', 1095, 28, 'TT-', [12, 7, 8, 2, 5, 10]],\n",
    "    [9, 'E194', '符號', 2, 122, '巴度', '徐雨石', 997, 27, '', [1, 4, 5, 7, 7, 5]],\n",
    "    [10, 'G072', '喜悅一生', 4, 121, '巫顯東 (-2)', '鄭俊偉', 1154, 26, 'B/TT', [2, 1, 4, 5, 10, 5]],\n",
    "    [11, 'H040', '小鳥', 10, 117, '蔡明紹', '葉楚航', 1011, 22, 'B', [10, 10, 10, 12, 7, 9]],\n",
    "    [12, 'H285', '鑽石福將', 11, 115, '潘明輝 (-2)', '蔡約翰', 1118, 17, '', [8, 6, 5, 7, 7, 6]],\n",
    "    [13, 'E409', '綠登', 7, 115, '楊明綸', '蘇偉賢', 1112, 16, 'PC/TT', [6, 7, 3, 4, 9, 4]]\n",
    "]\n",
    "# Extract all relevant features for prediction\n",
    "horse_features = []\n",
    "for horse_info in input_data[8:]:\n",
    "    horse_features.append([\n",
    "        horse_info[3],       # Position\n",
    "        horse_info[4],       # Actual weight\n",
    "        len(horse_info[10])  # Number of previous runs\n",
    "    ])\n",
    "\n",
    "# Reshape input features to match the expected shape of the model\n",
    "input_features_reshaped = np.array(horse_features)  # Convert to numpy array\n",
    "\n",
    "# Make predictions using the trained model\n",
    "predictions = model.predict(input_features_reshaped)\n",
    "\n",
    "# Assuming the first column represents the probability of winning\n",
    "horse_probabilities = predictions[0]\n",
    "\n",
    "# Sort the horses based on their probabilities\n",
    "sorted_indices = np.argsort(horse_probabilities)[::-1]\n",
    "\n",
    "# Get the top 4 horses with the highest probabilities of winning\n",
    "top_4_indices = sorted_indices[:4]\n",
    "top_4_horses = [input_data[index + 8] for index in top_4_indices]  # Extract horse information from the input data\n",
    "\n",
    "print(\"Top 4 horses with the highest probabilities of winning:\")\n",
    "for index, horse_info in zip(top_4_indices, top_4_horses):\n",
    "    print(f\"Horse {index + 1}: {horse_info[2]}\")  # Print horse name"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
